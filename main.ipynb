{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv('mobile_addiction.csv',encoding='utf-8')",
   "metadata": {
    "collapsed": false
   },
   "id": "6ceb594ff62e17cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Knowing The Data",
   "id": "59883c3a445b6a5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#know the shape of the data\n",
    "print(df.shape)"
   ],
   "id": "d877d065d429a8a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#know the data types of the coulumns\n",
    "print(df.info())"
   ],
   "id": "70d9fc8e67915ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#take a look of the data\n",
    "df.head()"
   ],
   "id": "9c96efd972a71355",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#descriing numerical values\n",
    "df.describe()"
   ],
   "id": "b4d05e2f9f97eba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#descriing categorical values\n",
    "df.describe(include='object')"
   ],
   "id": "8601e8a4fa2f0d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#to get columns names\n",
    "df.columns"
   ],
   "id": "3a6de20ab1c03136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['addicted'].value_counts()",
   "id": "441ce39b90391050",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Check for null values\n",
    "print(df.isnull().sum())"
   ],
   "id": "2201423fea37a269",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop unnecessary index column\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ],
   "id": "5cdf4d00df1c7d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#to get columns names\n",
    "df.columns"
   ],
   "id": "57d81724ecce8828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#to show outliers for all numerical columns\n",
    "for column in df.select_dtypes(include=['number']).columns:\n",
    "\tfig = px.box(df, x=column, title= f'Box plot for {column}')\n",
    "\tfig.show()\n"
   ],
   "id": "5d2311ef39779c26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Almost there is no outliers in this data set*",
   "id": "625ca7214b847ddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    'daily_screen_time', 'app_sessions', 'social_media_usage',\n",
    "    'gaming_time', 'notifications', 'night_usage', 'age',\n",
    "    'work_study_hours', 'stress_level', 'apps_installed'\n",
    "]\n",
    "\n",
    "for feature in features:\n",
    "    binned_col = f'{feature}_binned'\n",
    "\n",
    "    try:\n",
    "        unique_vals = df[feature].nunique()\n",
    "\n",
    "        # Use qcut for features with many unique values\n",
    "        if unique_vals >= 10:\n",
    "            bin_edges = pd.qcut(df[feature], q=5, retbins=True, duplicates='drop')[1]\n",
    "            num_bins = len(bin_edges) - 1\n",
    "            labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High'][:num_bins]\n",
    "            df[binned_col] = pd.qcut(df[feature], q=num_bins, labels=labels)\n",
    "        else:\n",
    "            # Fallback: cut into equal-width bins\n",
    "            df[binned_col] = pd.cut(df[feature], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "        # Plot\n",
    "        sns.countplot(x=binned_col, hue='addicted', data=df)\n",
    "        plt.title(f'Addiction Status by {feature.replace(\"_\", \" \").title()}')\n",
    "        plt.xlabel(feature.replace('_', ' ').title())\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {feature} due to error: {e}\")"
   ],
   "id": "cc7161ebed82707c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I noticed that in the social media, gaming time, and night usage, when the time increased I got fewer addicted persons so I decided to calculate the proportions within each bin instead of count\n",
   "id": "8eb6413f8f6ef3e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Features to visualize\n",
    "features = [\n",
    "    'daily_screen_time', 'app_sessions', 'social_media_usage',\n",
    "    'gaming_time', 'notifications', 'night_usage', 'age',\n",
    "    'work_study_hours', 'stress_level', 'apps_installed'\n",
    "]\n",
    "\n",
    "# Loop through each feature\n",
    "for feature in features:\n",
    "    binned_col = f'{feature}_binned'\n",
    "\n",
    "    unique_vals = df[feature].nunique()\n",
    "\n",
    "    # Choose binning strategy based on value spread\n",
    "    if unique_vals >= 10:\n",
    "        # Quantile binning\n",
    "        bin_edges = pd.qcut(df[feature], q=5, retbins=True, duplicates='drop')[1]\n",
    "        num_bins = len(bin_edges) - 1\n",
    "        labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High'][:num_bins]\n",
    "        df[binned_col] = pd.qcut(df[feature], q=num_bins, labels=labels)\n",
    "    else:\n",
    "        # Equal-width binning for low-uniqueness features\n",
    "        df[binned_col] = pd.cut(df[feature], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "    # Group and calculate percentage with observed=True to suppress warnings\n",
    "    grouped = df.groupby([binned_col, 'addicted'], observed=True).size().reset_index(name='count')\n",
    "    total_per_bin = grouped.groupby(binned_col, observed=True)['count'].transform('sum')\n",
    "    grouped['percentage'] = grouped['count'] / total_per_bin * 100\n",
    "\n",
    "    # Pivot for stacked bar plot\n",
    "    pivot = grouped.pivot(index=binned_col, columns='addicted', values='percentage').fillna(0)\n",
    "\n",
    "    # SAFELY rename columns based on presence\n",
    "    column_map = {0: 'Not Addicted', 1: 'Addicted'}\n",
    "    pivot.columns = [column_map.get(c, str(c)) for c in pivot.columns]\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    pivot.plot(kind='bar', stacked=True, figsize=(8, 6), colormap='Set2')\n",
    "    plt.title(f'Addiction Percentage by {feature.replace(\"_\", \" \").title()}')\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.legend(title='Addiction Status')\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "45ece27da6122864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.heatmap(df[features].corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()\n"
   ],
   "id": "a105a043b9ecd671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Note:* No features are truly redundant, but some are highly related, social_media_usage, gaming_time, night_usage ⟶ part of daily_screen_time, and app_sessions might correlate with apps_installed",
   "id": "65cf5b148cd9a362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['addicted'] = df['addicted'].map({'not addicted': 0, 'addicted': 1}).astype(int)",
   "id": "1119660a3003e506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df['addicted'].unique())  # Should print: [1 0]",
   "id": "210a122adddac10d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Addicted column which its values are objects has been encoded to 1 and 0*",
   "id": "dd3ba207e93decb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Matrix (Including Addicted)\")\n",
    "plt.show()\n"
   ],
   "id": "9890fce78c936f98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Note:* This heat map indicates that there is a correlation with addicted feature and all other features",
   "id": "f1a4e4c6aacca5f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models:",
   "id": "888c8f839aa99ea4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###      1- Logistic Regression",
   "id": "6b07b24d15d01f54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Work on a copy to avoid modifying the original dataset\n",
    "df_model = df.copy()\n",
    "\n",
    "# Encode 'addicted' column (from 'addicted'/'not addicted' to 1/0)\n",
    "df_model['addicted'] = df_model['addicted'].replace({'addicted': 1, 'not addicted': 0}).astype(int)\n",
    "\n",
    "# Drop non-numeric columns (like binned categorical features)\n",
    "df_model = df_model.select_dtypes(include=['number'])\n",
    "\n",
    "# Define features and target\n",
    "X = df_model.drop(columns='addicted')\n",
    "y = df_model['addicted']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ىScale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_proba = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "deffc8fbbc4f04fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Logistic Regression Performance\n",
    "Accuracy: 98%\n",
    "Precision & Recall (both classes): 98%\n",
    "Confusion Matrix: Only 26 false positives and 26 false negatives out of 2718 samples.\n",
    "ROC AUC: Very likely near 0.98 (since not shown but implied)*\n",
    "\n"
   ],
   "id": "fb37ef807c95782b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###      2- Random Forest Classifier",
   "id": "44cc26842b07f624"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ],
   "id": "a66b2803e9ed0682",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: We're using the unscaled X_train and X_test because tree-based models like Random Forest don’t require feature scaling.",
   "id": "f58135173361332d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Accuracy: 98.09% (very slightly better than Logistic Regression)\n",
    "ROC AUC: 0.998 → significantly higher than Logistic Regression (better probability calibration)\n",
    "Precision/Recall/F1: 98% for both classes\n",
    "Confusion Matrix: 25 false positives and 27 false negatives*"
   ],
   "id": "2303d90eb85aa4e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d7d196bbeb13379c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
